{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin init\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:100% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete init\n"
     ]
    }
   ],
   "source": [
    "#region Init\n",
    "print(\"Begin init\")\n",
    "%run -i init_notebook.ipynb\n",
    "import tensorflow as tf\n",
    "%load_ext tensorboard\n",
    "import pandas as pd\n",
    "\n",
    "import datetime, os\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "logs_base_dir = \"../.logs\"\n",
    "\n",
    "print(\"Complete init\")\n",
    "#endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Strategy <tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy object at 0x000001F8771100A0>\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# assert tf.config.experimental.get_memory_growth(physical_devices[0])\n",
    "\n",
    "# Set logs for tf\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# # # create virtual gpu\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#    # Create N virtual GPUs with 1GB memory each\n",
    "#    try:\n",
    "#      tf.config.experimental.set_virtual_device_configuration(\n",
    "#          gpus[0],\n",
    "#          [\n",
    "#              tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024),\n",
    "#              tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)\n",
    "#          ])\n",
    "#      logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#      print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#    except RuntimeError as e:\n",
    "#      # Virtual devices must be set before GPUs have been initialized\n",
    "#      print(e)\n",
    "\n",
    "strategy = tf.distribute.OneDeviceStrategy(\"/gpu:0\")\n",
    "print(\"Strategy\", strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA is ready\n"
     ]
    }
   ],
   "source": [
    "def generate_one_data():\n",
    "    def calculate_Y(x):\n",
    "        if (0.2 <= x[0] <= 0.6):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def invert_Y(y):\n",
    "        if y==0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    x = np.random.rand(5,)\n",
    "    data = {\n",
    "        'property1': x,\n",
    "        'property2': x,\n",
    "        'y': calculate_Y(x)\n",
    "    }\n",
    "    return data\n",
    "\n",
    "def value_to_tensor(value, x_keys, y_key):\n",
    "        x = [value.get(key) for key in x_keys]\n",
    "        y = [1] if value[y_key] == 1 else [0]\n",
    "        return x, y\n",
    "\n",
    "def generate_data(n):\n",
    "    data_example = generate_one_data()\n",
    "    columns = set(data_example.keys())\n",
    "    raw = {\"date\", \"close\", \"open\", \"date\", \"high\", \"loss\", \"low\", \"volume\", \"profit\", \"loss\", \"y\"}\n",
    "    x_keys = list(columns - raw)\n",
    "    x_keys.sort()\n",
    "\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    for i in range(n):\n",
    "        value = generate_one_data()\n",
    "        x, y = value_to_tensor(value, x_keys, \"y\")\n",
    "        all_x.append(x)\n",
    "        all_y.append(y)\n",
    "    return all_x, all_y\n",
    "\n",
    "train_x, train_y = generate_data(100000)\n",
    "test_x, test_y = generate_data(1000)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensors((train_x, train_y))\n",
    "test_dataset = tf.data.Dataset.from_tensors((test_x, test_y))\n",
    "\n",
    "print(\"DATA is ready\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save logs to ../.logs\\20210526-233305\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6995 - fn: 42784.0000 - fp: 15678.0000 - tn: 24477.0000 - tp: 17061.0000 - precision: 0.5211 - recall: 0.2851 - ba: 0.4154 - val_loss: 0.6704 - val_fn: 0.0000e+00 - val_fp: 408.0000 - val_tn: 0.0000e+00 - val_tp: 592.0000 - val_precision: 0.5920 - val_recall: 1.0000 - val_ba: 0.5920\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 1s 896ms/step - loss: 0.6690 - fn: 0.0000e+00 - fp: 40155.0000 - tn: 0.0000e+00 - tp: 59845.0000 - precision: 0.5985 - recall: 1.0000 - ba: 0.5985 - val_loss: 0.6693 - val_fn: 0.0000e+00 - val_fp: 408.0000 - val_tn: 0.0000e+00 - val_tp: 592.0000 - val_precision: 0.5920 - val_recall: 1.0000 - val_ba: 0.5920\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6664 - fn: 0.0000e+00 - fp: 40155.0000 - tn: 0.0000e+00 - tp: 59845.0000 - precision: 0.5985 - recall: 1.0000 - ba: 0.5985 - val_loss: 0.6588 - val_fn: 0.0000e+00 - val_fp: 408.0000 - val_tn: 0.0000e+00 - val_tp: 592.0000 - val_precision: 0.5920 - val_recall: 1.0000 - val_ba: 0.5920\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6560 - fn: 0.0000e+00 - fp: 40155.0000 - tn: 0.0000e+00 - tp: 59845.0000 - precision: 0.5985 - recall: 1.0000 - ba: 0.5985 - val_loss: 0.6466 - val_fn: 0.0000e+00 - val_fp: 408.0000 - val_tn: 0.0000e+00 - val_tp: 592.0000 - val_precision: 0.5920 - val_recall: 1.0000 - val_ba: 0.5920\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6446 - fn: 0.0000e+00 - fp: 40155.0000 - tn: 0.0000e+00 - tp: 59845.0000 - precision: 0.5985 - recall: 1.0000 - ba: 0.5985 - val_loss: 0.6334 - val_fn: 0.0000e+00 - val_fp: 408.0000 - val_tn: 0.0000e+00 - val_tp: 592.0000 - val_precision: 0.5920 - val_recall: 1.0000 - val_ba: 0.5920\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6317 - fn: 0.0000e+00 - fp: 40155.0000 - tn: 0.0000e+00 - tp: 59845.0000 - precision: 0.5985 - recall: 1.0000 - ba: 0.5985 - val_loss: 0.6177 - val_fn: 0.0000e+00 - val_fp: 408.0000 - val_tn: 0.0000e+00 - val_tp: 592.0000 - val_precision: 0.5920 - val_recall: 1.0000 - val_ba: 0.5920\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6153 - fn: 0.0000e+00 - fp: 40155.0000 - tn: 0.0000e+00 - tp: 59845.0000 - precision: 0.5985 - recall: 1.0000 - ba: 0.5985 - val_loss: 0.5994 - val_fn: 0.0000e+00 - val_fp: 408.0000 - val_tn: 0.0000e+00 - val_tp: 592.0000 - val_precision: 0.5920 - val_recall: 1.0000 - val_ba: 0.5920\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.5965 - fn: 0.0000e+00 - fp: 40155.0000 - tn: 0.0000e+00 - tp: 59845.0000 - precision: 0.5985 - recall: 1.0000 - ba: 0.5985 - val_loss: 0.5750 - val_fn: 40.0000 - val_fp: 371.0000 - val_tn: 37.0000 - val_tp: 552.0000 - val_precision: 0.5980 - val_recall: 0.9324 - val_ba: 0.5890\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.5740 - fn: 4348.0000 - fp: 35860.0000 - tn: 4295.0000 - tp: 55497.0000 - precision: 0.6075 - recall: 0.9273 - ba: 0.5979 - val_loss: 0.5499 - val_fn: 142.0000 - val_fp: 194.0000 - val_tn: 214.0000 - val_tp: 450.0000 - val_precision: 0.6988 - val_recall: 0.7601 - val_ba: 0.6640\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5516 - fn: 16049.0000 - fp: 17919.0000 - tn: 22236.0000 - tp: 43796.0000 - precision: 0.7096 - recall: 0.7318 - ba: 0.6603 - val_loss: 0.5275 - val_fn: 190.0000 - val_fp: 143.0000 - val_tn: 265.0000 - val_tp: 402.0000 - val_precision: 0.7376 - val_recall: 0.6791 - val_ba: 0.6670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.5285 - fn: 20094.0000 - fp: 12513.0000 - tn: 27642.0000 - tp: 39751.0000 - precision: 0.7606 - recall: 0.6642 - ba: 0.6739 - val_loss: 0.5083 - val_fn: 194.0000 - val_fp: 130.0000 - val_tn: 278.0000 - val_tp: 398.0000 - val_precision: 0.7538 - val_recall: 0.6723 - val_ba: 0.6760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.5076 - fn: 20908.0000 - fp: 10772.0000 - tn: 29383.0000 - tp: 38937.0000 - precision: 0.7833 - recall: 0.6506 - ba: 0.6832 - val_loss: 0.4829 - val_fn: 202.0000 - val_fp: 84.0000 - val_tn: 324.0000 - val_tp: 390.0000 - val_precision: 0.8228 - val_recall: 0.6588 - val_ba: 0.7140\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.4869 - fn: 21900.0000 - fp: 6937.0000 - tn: 33218.0000 - tp: 37945.0000 - precision: 0.8454 - recall: 0.6341 - ba: 0.7116 - val_loss: 0.4608 - val_fn: 199.0000 - val_fp: 77.0000 - val_tn: 331.0000 - val_tp: 393.0000 - val_precision: 0.8362 - val_recall: 0.6639 - val_ba: 0.7240\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.4647 - fn: 21511.0000 - fp: 6453.0000 - tn: 33702.0000 - tp: 38334.0000 - precision: 0.8559 - recall: 0.6406 - ba: 0.7204 - val_loss: 0.4364 - val_fn: 196.0000 - val_fp: 72.0000 - val_tn: 336.0000 - val_tp: 396.0000 - val_precision: 0.8462 - val_recall: 0.6689 - val_ba: 0.7320\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.4409 - fn: 21205.0000 - fp: 5816.0000 - tn: 34339.0000 - tp: 38640.0000 - precision: 0.8692 - recall: 0.6457 - ba: 0.7298 - val_loss: 0.4044 - val_fn: 206.0000 - val_fp: 39.0000 - val_tn: 369.0000 - val_tp: 386.0000 - val_precision: 0.9082 - val_recall: 0.6520 - val_ba: 0.7550\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.4159 - fn: 22133.0000 - fp: 3420.0000 - tn: 36735.0000 - tp: 37712.0000 - precision: 0.9169 - recall: 0.6302 - ba: 0.7445 - val_loss: 0.3888 - val_fn: 171.0000 - val_fp: 74.0000 - val_tn: 334.0000 - val_tp: 421.0000 - val_precision: 0.8505 - val_recall: 0.7111 - val_ba: 0.7550\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.3907 - fn: 17679.0000 - fp: 5803.0000 - tn: 34352.0000 - tp: 42166.0000 - precision: 0.8790 - recall: 0.7046 - ba: 0.7652 - val_loss: 0.3537 - val_fn: 106.0000 - val_fp: 9.0000 - val_tn: 399.0000 - val_tp: 486.0000 - val_precision: 0.9818 - val_recall: 0.8209 - val_ba: 0.8850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.3708 - fn: 12887.0000 - fp: 1441.0000 - tn: 38714.0000 - tp: 46958.0000 - precision: 0.9702 - recall: 0.7847 - ba: 0.8567 - val_loss: 0.3202 - val_fn: 42.0000 - val_fp: 52.0000 - val_tn: 356.0000 - val_tp: 550.0000 - val_precision: 0.9136 - val_recall: 0.9291 - val_ba: 0.9060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.3250 - fn: 5104.0000 - fp: 4466.0000 - tn: 35689.0000 - tp: 54741.0000 - precision: 0.9246 - recall: 0.9147 - ba: 0.9043 - val_loss: 0.2946 - val_fn: 23.0000 - val_fp: 60.0000 - val_tn: 348.0000 - val_tp: 569.0000 - val_precision: 0.9046 - val_recall: 0.9611 - val_ba: 0.9170\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.2970 - fn: 2163.0000 - fp: 5347.0000 - tn: 34808.0000 - tp: 57682.0000 - precision: 0.9152 - recall: 0.9639 - ba: 0.9249 - val_loss: 0.2694 - val_fn: 39.0000 - val_fp: 41.0000 - val_tn: 367.0000 - val_tp: 553.0000 - val_precision: 0.9310 - val_recall: 0.9341 - val_ba: 0.9200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2826 - fn: 3708.0000 - fp: 4272.0000 - tn: 35883.0000 - tp: 56137.0000 - precision: 0.9293 - recall: 0.9380 - ba: 0.9202 - val_loss: 0.2352 - val_fn: 19.0000 - val_fp: 53.0000 - val_tn: 355.0000 - val_tp: 573.0000 - val_precision: 0.9153 - val_recall: 0.9679 - val_ba: 0.9280\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.2370 - fn: 1798.0000 - fp: 4521.0000 - tn: 35634.0000 - tp: 58047.0000 - precision: 0.9277 - recall: 0.9700 - ba: 0.9368 - val_loss: 0.2096 - val_fn: 23.0000 - val_fp: 43.0000 - val_tn: 365.0000 - val_tp: 569.0000 - val_precision: 0.9297 - val_recall: 0.9611 - val_ba: 0.9340\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2112 - fn: 2563.0000 - fp: 3652.0000 - tn: 36503.0000 - tp: 57282.0000 - precision: 0.9401 - recall: 0.9572 - ba: 0.9378 - val_loss: 0.1960 - val_fn: 46.0000 - val_fp: 23.0000 - val_tn: 385.0000 - val_tp: 546.0000 - val_precision: 0.9596 - val_recall: 0.9223 - val_ba: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.2063 - fn: 5014.0000 - fp: 1817.0000 - tn: 38338.0000 - tp: 54831.0000 - precision: 0.9679 - recall: 0.9162 - ba: 0.9317 - val_loss: 0.1786 - val_fn: 16.0000 - val_fp: 51.0000 - val_tn: 357.0000 - val_tp: 576.0000 - val_precision: 0.9187 - val_recall: 0.9730 - val_ba: 0.9330\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1741 - fn: 1517.0000 - fp: 4457.0000 - tn: 35698.0000 - tp: 58328.0000 - precision: 0.9290 - recall: 0.9747 - ba: 0.9403 - val_loss: 0.1515 - val_fn: 10.0000 - val_fp: 37.0000 - val_tn: 371.0000 - val_tp: 582.0000 - val_precision: 0.9402 - val_recall: 0.9831 - val_ba: 0.9530\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1489 - fn: 938.0000 - fp: 3986.0000 - tn: 36169.0000 - tp: 58907.0000 - precision: 0.9366 - recall: 0.9843 - ba: 0.9508 - val_loss: 0.1477 - val_fn: 27.0000 - val_fp: 25.0000 - val_tn: 383.0000 - val_tp: 565.0000 - val_precision: 0.9576 - val_recall: 0.9544 - val_ba: 0.9480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1508 - fn: 3190.0000 - fp: 2584.0000 - tn: 37571.0000 - tp: 56655.0000 - precision: 0.9564 - recall: 0.9467 - ba: 0.9423 - val_loss: 0.1490 - val_fn: 19.0000 - val_fp: 41.0000 - val_tn: 367.0000 - val_tp: 573.0000 - val_precision: 0.9332 - val_recall: 0.9679 - val_ba: 0.9400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1428 - fn: 2162.0000 - fp: 3665.0000 - tn: 36490.0000 - tp: 57683.0000 - precision: 0.9403 - recall: 0.9639 - ba: 0.9417 - val_loss: 0.1151 - val_fn: 28.0000 - val_fp: 18.0000 - val_tn: 390.0000 - val_tp: 564.0000 - val_precision: 0.9691 - val_recall: 0.9527 - val_ba: 0.9540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1150 - fn: 2565.0000 - fp: 1313.0000 - tn: 38842.0000 - tp: 57280.0000 - precision: 0.9776 - recall: 0.9571 - ba: 0.9612 - val_loss: 0.1121 - val_fn: 21.0000 - val_fp: 22.0000 - val_tn: 386.0000 - val_tp: 571.0000 - val_precision: 0.9629 - val_recall: 0.9645 - val_ba: 0.9570\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1108 - fn: 2105.0000 - fp: 2020.0000 - tn: 38135.0000 - tp: 57740.0000 - precision: 0.9662 - recall: 0.9648 - ba: 0.9588 - val_loss: 0.1317 - val_fn: 8.0000 - val_fp: 51.0000 - val_tn: 357.0000 - val_tp: 584.0000 - val_precision: 0.9197 - val_recall: 0.9865 - val_ba: 0.9410\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1208 - fn: 718.0000 - fp: 4536.0000 - tn: 35619.0000 - tp: 59127.0000 - precision: 0.9287 - recall: 0.9880 - ba: 0.9475 - val_loss: 0.1034 - val_fn: 21.0000 - val_fp: 22.0000 - val_tn: 386.0000 - val_tp: 571.0000 - val_precision: 0.9629 - val_recall: 0.9645 - val_ba: 0.9570\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1011 - fn: 2214.0000 - fp: 1763.0000 - tn: 38392.0000 - tp: 57631.0000 - precision: 0.9703 - recall: 0.9630 - ba: 0.9602 - val_loss: 0.0903 - val_fn: 20.0000 - val_fp: 18.0000 - val_tn: 390.0000 - val_tp: 572.0000 - val_precision: 0.9695 - val_recall: 0.9662 - val_ba: 0.9620\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0875 - fn: 1932.0000 - fp: 1115.0000 - tn: 39040.0000 - tp: 57913.0000 - precision: 0.9811 - recall: 0.9677 - ba: 0.9695 - val_loss: 0.0997 - val_fn: 17.0000 - val_fp: 27.0000 - val_tn: 381.0000 - val_tp: 575.0000 - val_precision: 0.9551 - val_recall: 0.9713 - val_ba: 0.9560\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0938 - fn: 1406.0000 - fp: 2450.0000 - tn: 37705.0000 - tp: 58439.0000 - precision: 0.9598 - recall: 0.9765 - ba: 0.9614 - val_loss: 0.1007 - val_fn: 23.0000 - val_fp: 21.0000 - val_tn: 387.0000 - val_tp: 569.0000 - val_precision: 0.9644 - val_recall: 0.9611 - val_ba: 0.9560\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0971 - fn: 2423.0000 - fp: 1781.0000 - tn: 38374.0000 - tp: 57422.0000 - precision: 0.9699 - recall: 0.9595 - ba: 0.9580 - val_loss: 0.0903 - val_fn: 6.0000 - val_fp: 34.0000 - val_tn: 374.0000 - val_tp: 586.0000 - val_precision: 0.9452 - val_recall: 0.9899 - val_ba: 0.9600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0825 - fn: 527.0000 - fp: 2772.0000 - tn: 37383.0000 - tp: 59318.0000 - precision: 0.9554 - recall: 0.9912 - ba: 0.9670 - val_loss: 0.0760 - val_fn: 14.0000 - val_fp: 17.0000 - val_tn: 391.0000 - val_tp: 578.0000 - val_precision: 0.9714 - val_recall: 0.9764 - val_ba: 0.9690\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0714 - fn: 1081.0000 - fp: 1416.0000 - tn: 38739.0000 - tp: 58764.0000 - precision: 0.9765 - recall: 0.9819 - ba: 0.9750 - val_loss: 0.0845 - val_fn: 27.0000 - val_fp: 11.0000 - val_tn: 397.0000 - val_tp: 565.0000 - val_precision: 0.9809 - val_recall: 0.9544 - val_ba: 0.9620\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0818 - fn: 2566.0000 - fp: 702.0000 - tn: 39453.0000 - tp: 57279.0000 - precision: 0.9879 - recall: 0.9571 - ba: 0.9673 - val_loss: 0.0909 - val_fn: 11.0000 - val_fp: 31.0000 - val_tn: 377.0000 - val_tp: 581.0000 - val_precision: 0.9493 - val_recall: 0.9814 - val_ba: 0.9580\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0841 - fn: 982.0000 - fp: 2775.0000 - tn: 37380.0000 - tp: 58863.0000 - precision: 0.9550 - recall: 0.9836 - ba: 0.9624 - val_loss: 0.0758 - val_fn: 10.0000 - val_fp: 21.0000 - val_tn: 387.0000 - val_tp: 582.0000 - val_precision: 0.9652 - val_recall: 0.9831 - val_ba: 0.9690\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0714 - fn: 1320.0000 - fp: 1621.0000 - tn: 38534.0000 - tp: 58525.0000 - precision: 0.9730 - recall: 0.9779 - ba: 0.9706 - val_loss: 0.0655 - val_fn: 8.0000 - val_fp: 14.0000 - val_tn: 394.0000 - val_tp: 584.0000 - val_precision: 0.9766 - val_recall: 0.9865 - val_ba: 0.9780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0616 - fn: 933.0000 - fp: 1183.0000 - tn: 38972.0000 - tp: 58912.0000 - precision: 0.9803 - recall: 0.9844 - ba: 0.9788 - val_loss: 0.0736 - val_fn: 12.0000 - val_fp: 21.0000 - val_tn: 387.0000 - val_tp: 580.0000 - val_precision: 0.9651 - val_recall: 0.9797 - val_ba: 0.9670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0706 - fn: 1245.0000 - fp: 1700.0000 - tn: 38455.0000 - tp: 58600.0000 - precision: 0.9718 - recall: 0.9792 - ba: 0.9706 - val_loss: 0.0750 - val_fn: 20.0000 - val_fp: 12.0000 - val_tn: 396.0000 - val_tp: 572.0000 - val_precision: 0.9795 - val_recall: 0.9662 - val_ba: 0.9680\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0725 - fn: 2322.0000 - fp: 771.0000 - tn: 39384.0000 - tp: 57523.0000 - precision: 0.9868 - recall: 0.9612 - ba: 0.9691 - val_loss: 0.0685 - val_fn: 6.0000 - val_fp: 26.0000 - val_tn: 382.0000 - val_tp: 586.0000 - val_precision: 0.9575 - val_recall: 0.9899 - val_ba: 0.9680\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0630 - fn: 389.0000 - fp: 2068.0000 - tn: 38087.0000 - tp: 59456.0000 - precision: 0.9664 - recall: 0.9935 - ba: 0.9754 - val_loss: 0.0595 - val_fn: 7.0000 - val_fp: 19.0000 - val_tn: 389.0000 - val_tp: 585.0000 - val_precision: 0.9685 - val_recall: 0.9882 - val_ba: 0.9740\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0547 - fn: 525.0000 - fp: 1353.0000 - tn: 38802.0000 - tp: 59320.0000 - precision: 0.9777 - recall: 0.9912 - ba: 0.9812 - val_loss: 0.0627 - val_fn: 15.0000 - val_fp: 9.0000 - val_tn: 399.0000 - val_tp: 577.0000 - val_precision: 0.9846 - val_recall: 0.9747 - val_ba: 0.9760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0592 - fn: 1692.0000 - fp: 585.0000 - tn: 39570.0000 - tp: 58153.0000 - precision: 0.9900 - recall: 0.9717 - ba: 0.9772 - val_loss: 0.0685 - val_fn: 12.0000 - val_fp: 21.0000 - val_tn: 387.0000 - val_tp: 580.0000 - val_precision: 0.9651 - val_recall: 0.9797 - val_ba: 0.9670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0651 - fn: 1091.0000 - fp: 1769.0000 - tn: 38386.0000 - tp: 58754.0000 - precision: 0.9708 - recall: 0.9818 - ba: 0.9714 - val_loss: 0.0636 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 394.0000 - val_tp: 577.0000 - val_precision: 0.9763 - val_recall: 0.9747 - val_ba: 0.9710\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0582 - fn: 1437.0000 - fp: 914.0000 - tn: 39241.0000 - tp: 58408.0000 - precision: 0.9846 - recall: 0.9760 - ba: 0.9765 - val_loss: 0.0563 - val_fn: 5.0000 - val_fp: 19.0000 - val_tn: 389.0000 - val_tp: 587.0000 - val_precision: 0.9686 - val_recall: 0.9916 - val_ba: 0.9760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0505 - fn: 339.0000 - fp: 1393.0000 - tn: 38762.0000 - tp: 59506.0000 - precision: 0.9771 - recall: 0.9943 - ba: 0.9827 - val_loss: 0.0544 - val_fn: 8.0000 - val_fp: 15.0000 - val_tn: 393.0000 - val_tp: 584.0000 - val_precision: 0.9750 - val_recall: 0.9865 - val_ba: 0.9770\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0497 - fn: 589.0000 - fp: 1116.0000 - tn: 39039.0000 - tp: 59256.0000 - precision: 0.9815 - recall: 0.9902 - ba: 0.9829 - val_loss: 0.0610 - val_fn: 21.0000 - val_fp: 8.0000 - val_tn: 400.0000 - val_tp: 571.0000 - val_precision: 0.9862 - val_recall: 0.9645 - val_ba: 0.9710\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "********************************************************************************************************************************************************************************************************\n",
      "Finished training the model\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0610 - fn: 21.0000 - fp: 8.0000 - tn: 400.0000 - tp: 571.0000 - precision: 0.9862 - recall: 0.9645 - ba: 0.9710\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Finished evaluating the model [0.06096821650862694, 21.0, 8.0, 400.0, 571.0, 0.9861830472946167, 0.9645270109176636, 0.9710000157356262]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def get_metrics():\n",
    "    metrics = [\n",
    "        keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        keras.metrics.TruePositives(name=\"tp\"),\n",
    "        keras.metrics.Precision(name=\"precision\"),\n",
    "        keras.metrics.Recall(name=\"recall\"),\n",
    "        keras.metrics.BinaryAccuracy(name=\"ba\")\n",
    "    ]\n",
    "    return metrics\n",
    "\n",
    "def build_model(input_shape):\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(input_shape)),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(48, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(48, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(48, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "log_dir = os.path.join(logs_base_dir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir, histogram_freq=1)\n",
    "print(\"Save logs to\", log_dir)\n",
    "\n",
    "with strategy.scope():\n",
    "    model = build_model(input_shape=(2, 5))\n",
    "    metrics = get_metrics()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=metrics)\n",
    "\n",
    "    training_history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data = test_dataset,\n",
    "        epochs=50,\n",
    "        batch_size=300,\n",
    "        shuffle=True,\n",
    "        callbacks=[tensorboard_callback])\n",
    "\n",
    "print(\"*\"*200)\n",
    "print(\"Finished training the model\")\n",
    "validation_result  = model.evaluate(test_dataset, batch_size=300)\n",
    "print(\"Finished evaluating the model\", validation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}